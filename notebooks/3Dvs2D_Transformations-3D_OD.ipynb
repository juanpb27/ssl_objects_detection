{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Object Detection\n",
    "### Comparison between training using 2D or 3D Transformations\n",
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Dependencies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a) General libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import cv2\n",
    "import pickle\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import deeptrack as dt\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import img_as_float\n",
    "from shapely.geometry import Point\n",
    "from matplotlib.patches import Rectangle\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c) Object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title\n",
    "class Preprocessor():\n",
    "\n",
    "  def __init__(self,\n",
    "               scales=[1, 2, 4]\n",
    "               ):\n",
    "    self.scales = scales\n",
    "\n",
    "  \n",
    "  def crop(self, image, x, y, wide):\n",
    "    cropped_image = image[y: y + wide, x: x + wide]\n",
    "\n",
    "    return cropped_image\n",
    "\n",
    "  def normalizate(self, image):\n",
    "    normalized_image = np.nan_to_num(image)\n",
    "    normalized_image = (normalized_image - np.quantile(normalized_image, 0.01)) / (np.quantile(normalized_image, 0.99) - np.quantile(normalized_image, 0.01))\n",
    "\n",
    "    return normalized_image\n",
    "\n",
    "\n",
    "  def resize(self, image, scale):\n",
    "    height, width = image.shape[:2]\n",
    "    new_width = int(width * scale)\n",
    "    new_height = int(height * scale)\n",
    "    resized_image = cv2.resize(image, (new_width, new_height))\n",
    "\n",
    "    return resized_image\n",
    "\n",
    "  def generate_pipeline(self, data, transformations):\n",
    "    pipeline = None\n",
    "    for transformation in transformations:\n",
    "        if pipeline is None:\n",
    "            pipeline = transformation\n",
    "        else:\n",
    "            pipeline = pipeline >> transformation\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "  def create_train_data(self, data, transformations):\n",
    "    # data -> an image o a list of images\n",
    "    normalized_images = [self.normalizate(image) for image in data]\n",
    "    training_images = [np.expand_dims(image, axis = -1) for image in normalized_images]\n",
    "\n",
    "    pipeline = self.generate_pipeline(training_images, transformations)\n",
    "    train_set = dt.Value(lambda: np.array(random.choice(training_images))) >> pipeline\n",
    "    train_set.plot()\n",
    "\n",
    "    return train_set\n",
    "\n",
    "  def load_images(self, data, plot=True):\n",
    "    original_image = self.normalizate(data)\n",
    "    input_set = [self.resize(original_image, scale) for scale in self.scales]\n",
    "\n",
    "    if plot:\n",
    "      fig, ax = plt.subplots(1, len(input_set), figsize=(25,5))\n",
    "      fig.tight_layout()\n",
    "      fig.suptitle('Scaled 3D images')\n",
    "      for index in range(len(input_set)):\n",
    "        ax[index].imshow(input_set[index])\n",
    "    \n",
    "    return input_set\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "class Trainer():\n",
    "\n",
    "  def __init__(self,\n",
    "               filepath,\n",
    "               model = dt.models.LodeSTAR(input_shape=(None, None, 1)),\n",
    "               callbacks = [None]\n",
    "               ):\n",
    "\n",
    "    self.model = model\n",
    "    self.filepath = filepath\n",
    "    self.callbacks = [\n",
    "        ModelCheckpoint(filepath=self.filepath,\n",
    "                        save_weights_only=True,\n",
    "                        monitor='consistency_loss',\n",
    "                        mode='min',\n",
    "                        save_best_only=True\n",
    "                        ),\n",
    "        EarlyStopping(monitor=\"total_loss\",\n",
    "                      patience=15,\n",
    "                      verbose=1,\n",
    "                      mode=\"auto\",\n",
    "                      restore_best_weights=True\n",
    "                      ),\n",
    "        LearningRateScheduler(lambda epoch, lr: lr if epoch < 10 else lr * np.exp(-0.1))\n",
    "    ]\n",
    "  \n",
    "  def fit(self, train_set, epochs=40, batch_size=8):\n",
    "    history = self.model.fit(\n",
    "        train_set,\n",
    "        epochs = epochs,\n",
    "        batch_size = batch_size,\n",
    "        callbacks = self.callbacks)\n",
    "\n",
    "    return history\n",
    "\n",
    "  def plot_performance(self, history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8,4))\n",
    "    fig.suptitle('Total loss and consistency loss')\n",
    "\n",
    "    ax1.plot(history.history['total_loss'])\n",
    "    ax1.set_title('Total loss')\n",
    "    ax1.set(xlabel='epoch', ylabel='loss')\n",
    "    ax1.set_ylim([0, 1.5])\n",
    "\n",
    "    ax2.plot(history.history['consistency_loss'])\n",
    "    ax2.set_title('Consitency loss')\n",
    "    ax2.set(xlabel='epoch', ylabel='loss')\n",
    "    ax2.set_ylim([0, 1.5])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "class Detector():\n",
    "\n",
    "  def __init__(self,\n",
    "               downsample,\n",
    "               alpha = 0.1,\n",
    "               cutoff = 0.998,\n",
    "               mode = \"quantile\",\n",
    "               colors = 'rgb',\n",
    "               model = dt.models.LodeSTAR(input_shape=(None, None, 1)),\n",
    "               ):\n",
    "    self.downsample = downsample\n",
    "    self.alpha = alpha\n",
    "    self.cutoff = cutoff\n",
    "    self.mode = mode\n",
    "    self.colors = colors\n",
    "    self.model = model\n",
    "\n",
    "  def detect(self, image, plot=True):\n",
    "    test_set = image[np.newaxis, :, :, np.newaxis]\n",
    "    test_image = test_set[:, ::self.downsample, ::self.downsample, :]\n",
    "\n",
    "    detections = self.model.predict_and_detect(test_image, alpha=self.alpha, beta=1-self.alpha, cutoff=self.cutoff, mode=self.mode)[0]\n",
    "    detections[:, 1] = detections[:, 1] * self.downsample\n",
    "    detections[:, 0] = detections[:, 0] * self.downsample\n",
    "\n",
    "    return detections\n",
    "\n",
    "  def detect_all(self, images, plot=False):\n",
    "    detections = []\n",
    "    \n",
    "    if plot:\n",
    "      fig, ax = plt.subplots(1, len(images), figsize=(25, 5))\n",
    "      fig.tight_layout()\n",
    "      fig.suptitle('Detections')\n",
    "    \n",
    "    for index in range(len(images)):\n",
    "      det = self.detect(image=images[index])\n",
    "      detections.append(det)\n",
    "\n",
    "      if plot:\n",
    "        ax[index].imshow(images[index])\n",
    "        ax[index].scatter(detections[index][:, 1], detections[index][:, 0], color=self.colors[index])\n",
    "      \n",
    "    return detections\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "class Postprocessor():\n",
    "\n",
    "  def __init__(self,\n",
    "               wide=50,\n",
    "               scales=[1, 2, 4],\n",
    "               colors = 'rgb'\n",
    "               ):\n",
    "    self.wide = wide\n",
    "    self.scales = scales\n",
    "    self.colors = colors\n",
    "  \n",
    "  def scale_detections(self, detection, scale):\n",
    "    scaled_detection = detection * scale\n",
    "\n",
    "    return scaled_detection.tolist()\n",
    "\n",
    "  def create_boxes(self, detections):\n",
    "    list_detections = [Point((x,y)) for (y,x) in detections]\n",
    "    points = gpd.GeoSeries(list_detections)\n",
    "    boxes = points.buffer(self.wide, cap_style = 3)\n",
    "    bounds = np.array([boxes[index].bounds for index in range(len(boxes))])\n",
    "\n",
    "    return boxes, bounds\n",
    "\n",
    "  def NMSupression(self, boxes, overlapThresh):\n",
    "    # Malisiewicz et al. - non_max_suppression_fast\n",
    "    if len(boxes) == 0:\n",
    "      return []\n",
    "\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "      boxes = boxes.astype(\"float\")\n",
    "    pick = []\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    "\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(y2)\n",
    " \n",
    "    while len(idxs) > 0:\n",
    "      last = len(idxs) - 1\n",
    "      i = idxs[last]\n",
    "      pick.append(i)\n",
    "\n",
    "      xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "      yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "      xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "      yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\n",
    "      w = np.maximum(0, xx2 - xx1 + 1)\n",
    "      h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "      overlap = (w * h) / area[idxs[:last]]\n",
    "\n",
    "      idxs = np.delete(idxs, np.concatenate(([last],\n",
    "        np.where(overlap > overlapThresh)[0])))\n",
    "      \n",
    "    return boxes[pick].astype(\"int\")\n",
    "\n",
    "  def apply_nms(self, image, list_bounds, figsize = (15,15), overlapThresh=0.3):\n",
    "    all_bounds = [bounds.tolist() for bounds in list_bounds]\n",
    "    final_bounds = []\n",
    "\n",
    "    for index in range(len(all_bounds)):\n",
    "      final_bounds += all_bounds[index]\n",
    "\n",
    "    final_bounds = np.array(final_bounds)\n",
    "    final_detections = self.NMSupression(final_bounds,\n",
    "                                         overlapThresh=overlapThresh)\n",
    "    self.plot_results(image, final_detections, figsize)\n",
    "\n",
    "    return final_detections\n",
    "\n",
    "\n",
    "  def plot_boxes(self, test_image, detections, figsize=(15, 15), plot=True):\n",
    "    list_boxes, list_bounds, scaled_detections = [], [], []\n",
    "\n",
    "    if plot:\n",
    "      fig, ax = plt.subplots(figsize=figsize)\n",
    "      plt.imshow(test_image)\n",
    "\n",
    "    for index in range(len(detections)):\n",
    "      scaled_det = self.scale_detections(detections[index], self.scales[index])\n",
    "      scaled_detections.append(scaled_det)\n",
    "\n",
    "      boxes, bounds = self.create_boxes(scaled_detections[index])\n",
    "      list_boxes.append(boxes)\n",
    "      list_bounds.append(bounds)\n",
    "\n",
    "      if plot:\n",
    "        boxes.boundary.plot(ax=ax, color = self.colors[index])\n",
    "\n",
    "    return list_bounds\n",
    "\n",
    "  def plot_results(self, image, boxes, figsize, color='red', lw=2):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(image)\n",
    "\n",
    "    wide = self.wide * 2\n",
    "    for i in range(len(boxes)):\n",
    "      rect = Rectangle((boxes[i][0], boxes[i][1]),wide,wide,\n",
    "                       edgecolor=color,\n",
    "                       facecolor='none',\n",
    "                       lw=lw)\n",
    "     \n",
    "      plt.gca().add_patch(rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_data, model, downsample=1, alpha=0.1, cutoff=0.99, mode=\"quantile\", plotPrevious=True):\n",
    "  preprocessor = Preprocessor()\n",
    "  input_set = preprocessor.load_images(test_data, plot=plotPrevious)\n",
    "  detector = Detector(downsample, model=model, alpha=alpha, cutoff=cutoff, mode=mode)\n",
    "  detections = detector.detect_all(input_set, plot=plotPrevious)\n",
    "  postprocessor = Postprocessor()\n",
    "  test_image = input_set[0]\n",
    "  bounds = postprocessor.plot_boxes(test_image, detections, plot=plotPrevious)\n",
    "  final_detections = postprocessor.apply_nms(test_image, bounds, figsize = (8,8))\n",
    "\n",
    "  return final_detections"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### d) Computing metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(gt_box, pred_box):\n",
    "    \"\"\"\n",
    "    Calcula el IoU (Intersection over Union) entre dos bounding boxes en formato [xmin, ymin, xmax, ymax].\n",
    "    \"\"\"\n",
    "    # Calcula la intersección entre los bounding boxes\n",
    "    x1 = np.maximum(gt_box[0], pred_box[0])\n",
    "    y1 = np.maximum(gt_box[1], pred_box[1])\n",
    "    x2 = np.minimum(gt_box[2], pred_box[2])\n",
    "    y2 = np.minimum(gt_box[3], pred_box[3])\n",
    "    intersection = np.maximum(0, x2 - x1) * np.maximum(0, y2 - y1)\n",
    "    \n",
    "    # Calcula la unión entre los bounding boxes\n",
    "    gt_area = (gt_box[2] - gt_box[0]) * (gt_box[3] - gt_box[1])\n",
    "    pred_area = (pred_box[2] - pred_box[0]) * (pred_box[3] - pred_box[1])\n",
    "    union = gt_area + pred_area - intersection\n",
    "    \n",
    "    # Calcula el IoU\n",
    "    iou = intersection / union\n",
    "    \n",
    "    return iou\n",
    "\n",
    "def confusion_matrix(tp, fp, fn):\n",
    "    \"\"\"\n",
    "    Construye una matriz de confusión a partir de los valores de verdaderos positivos (tp), falsos positivos (fp)\n",
    "    y falsos negativos (fn).\n",
    "    \"\"\"\n",
    "    tn = 0  # asumimos que no hay verdaderos negativos en este caso\n",
    "    \n",
    "    return np.array([[tp, fp], [fn, tn]])\n",
    "\n",
    "def plot_confusion_matrix(conf_matrix):\n",
    "    \"\"\"\n",
    "    Muestra la matriz de confusión como una gráfica utilizando la biblioteca matplotlib.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    im = ax.imshow(conf_matrix, cmap='Blues')\n",
    "\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        for j in range(conf_matrix.shape[1]):\n",
    "            ax.text(j, i, str(conf_matrix[i][j]), ha='center', va='center')\n",
    "\n",
    "    plt.colorbar(im)\n",
    "    plt.xticks([0, 1], ['Positive', 'Negative'])\n",
    "    plt.yticks([0, 1], ['Positive', 'Negative'])\n",
    "    plt.xlabel('Actual values')\n",
    "    plt.ylabel('Predicted values')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "def calculate_metrics(gt_boxes, pred_boxes, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Calcula la precisión, el recall, el puntaje F1 y el accuracy para un conjunto de bounding boxes del ground truth\n",
    "    y los predichos por una CNN.\n",
    "    gt_boxes y pred_boxes deben ser NumPy arrays de bounding boxes en el formato [[xmin, ymin, xmax, ymax], ...].\n",
    "    iou_threshold es el umbral de IoU para considerar que un bounding box predicho es correcto.\n",
    "    \"\"\"\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    for gt_box in gt_boxes:\n",
    "        gt_matched = False\n",
    "        for pred_box in pred_boxes:\n",
    "            iou = calculate_iou(gt_box, pred_box)\n",
    "            if iou >= iou_threshold:\n",
    "                tp += 1\n",
    "                gt_matched = True\n",
    "                break\n",
    "        if not gt_matched:\n",
    "            fn += 1\n",
    "    \n",
    "    for pred_box in pred_boxes:\n",
    "        pred_matched = False\n",
    "        for gt_box in gt_boxes:\n",
    "            iou = calculate_iou(gt_box, pred_box)\n",
    "            if iou >= iou_threshold:\n",
    "                pred_matched = True\n",
    "                break\n",
    "        if not pred_matched:\n",
    "            fp += 1\n",
    "    \n",
    "    if tp == 0 and fp == 0 and fn == 0:\n",
    "        # En caso de que no haya objetos en el ground truth o en las predicciones, todas las métricas son cero.\n",
    "        precision = 0.0\n",
    "        recall = 0.0\n",
    "        f1_score = 0.0\n",
    "        accuracy = 0.0\n",
    "    else:\n",
    "        precision = round(tp / float(tp + fp), 3)\n",
    "        recall = round(tp / float(tp + fn), 3)\n",
    "        if precision == 0 and recall == 0:\n",
    "            f1_score = 0.0\n",
    "        else:\n",
    "            f1_score = round(2 * ((precision * recall) / (precision + recall)), 3)\n",
    "        accuracy = round(tp / float(tp + fp + fn), 3)\n",
    "    \n",
    "    return precision, recall, f1_score, accuracy\n",
    "\n",
    "def generate_metrics(gt_boxes, pred_boxes, iou_threshold=0.5):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    total_tp = 0\n",
    "    total_fp = 0\n",
    "    total_fn = 0\n",
    "    \n",
    "    for gt_box in gt_boxes:\n",
    "        gt_matched = False\n",
    "        for pred_box in pred_boxes:\n",
    "            iou = calculate_iou(gt_box, pred_box)\n",
    "            if iou >= iou_threshold:\n",
    "                tp += 1\n",
    "                gt_matched = True\n",
    "                break\n",
    "        if not gt_matched:\n",
    "            fn += 1\n",
    "\n",
    "    total_tp += tp\n",
    "    total_fn += fn\n",
    "\n",
    "    for pred_box in pred_boxes:\n",
    "        pred_matched = False\n",
    "        for gt_box in gt_boxes:\n",
    "            iou = calculate_iou(gt_box, pred_box)\n",
    "            if iou >= iou_threshold:\n",
    "                pred_matched = True\n",
    "                break\n",
    "        if not pred_matched:\n",
    "            fp += 1\n",
    "\n",
    "    total_fp += fp\n",
    "    \n",
    "    precision, recall, f1_score, accuracy = calculate_metrics(gt_boxes, pred_boxes, iou_threshold)\n",
    "    conf_matrix = confusion_matrix(tp, fp, fn)\n",
    "    \n",
    "    return precision, recall, f1_score, accuracy, conf_matrix, [total_fp, total_fn, total_tp]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets loading (images and ground truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import scipy.io\n",
    "\n",
    "def load_data_file(mat_file_path, pkl_file_path, key):\n",
    "    # Load the image data from the .mat file\n",
    "    image_data = scipy.io.loadmat(mat_file_path)[key]\n",
    "\n",
    "    # Load the ground truth bounding boxes from the .pkl file\n",
    "    with open(pkl_file_path, 'rb') as file:\n",
    "        gt_boxes = pickle.load(file)\n",
    "\n",
    "    return image_data, gt_boxes\n",
    "\n",
    "def load_dataset(folder_path, key):\n",
    "    dataset = []\n",
    "    file_names = os.listdir(folder_path)\n",
    "    for file_name in file_names:\n",
    "        if file_name.endswith('.mat'):\n",
    "            mat_file_path = os.path.join(folder_path, file_name)\n",
    "            pkl_file_path = os.path.join(folder_path, f'{os.path.splitext(file_name)[0]}_gt.pkl')\n",
    "            if os.path.isfile(pkl_file_path):\n",
    "                data = load_data_file(mat_file_path, pkl_file_path, key)\n",
    "                dataset.append(data)\n",
    "    return dataset\n",
    "\n",
    "def display_images_with_gt(dataset):\n",
    "    for image_data, gt_boxes in dataset:\n",
    "        # Display the image\n",
    "        plt.imshow(image_data)\n",
    "        plt.axis('on')\n",
    "\n",
    "        # Display the ground truth bounding boxes\n",
    "        for box in gt_boxes:\n",
    "            x1, y1, x2, y2 = box\n",
    "            w = x2 - x1\n",
    "            h = y2 - y1\n",
    "            rect = plt.Rectangle((x1, y1), w, h, edgecolor='r', facecolor='none')\n",
    "            plt.gca().add_patch(rect)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1- Without surface base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noSurface_data_path = '../Data/MATLAB/ProcessedData/without_surface_base/'\n",
    "noSurface_key = 'Spz'\n",
    "noSurface_dataset = load_dataset(noSurface_data_path, noSurface_key)\n",
    "display_images_with_gt(noSurface_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2- With surface base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withSurface_data_path = '../Data/MATLAB/ProcessedData/with_surface_base'\n",
    "withSurface_key = 'ZcM_r'\n",
    "withSurface_dataset = load_dataset(withSurface_data_path, withSurface_key)\n",
    "display_images_with_gt(withSurface_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing and comparisons"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with 2D transformations\n",
    "filepath_2D = '../Model/checkpoints/2D_transformations'\n",
    "trainer_2D = Trainer(filepath_2D)\n",
    "trainer_2D.model = dt.models.LodeSTAR(input_shape=(None, None, 1))\n",
    "trainer_2D.model.load_weights(filepath_2D)\n",
    "\n",
    "# Model with 3D transformations\n",
    "filepath_3D = '../Model/checkpoints/3D_transformations'\n",
    "trainer_3D = Trainer(filepath_3D)\n",
    "trainer_3D.model = dt.models.LodeSTAR(input_shape=(None, None, 1))\n",
    "trainer_3D.model.load_weights(filepath_3D)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_object = 100 # 100\n",
    "wide = 20 # size of the training template\n",
    "downsample = size_object // wide"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Model trained with 2D vs 3D Transformations in images with surface remotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D images with surface remotion\n",
    "noSurface_test_images = [data[0] for data in noSurface_dataset]\n",
    "noSurface_groundTruth = [data[1] for data in noSurface_dataset]\n",
    "len(noSurface_test_images)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) 2D-transformations-trained model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detection settings\n",
    "alpha = 0.5 # 0.1\n",
    "cutoff = 0.9975 # 0.9985\n",
    "mode = \"quantile\"\n",
    "\n",
    "detected_boxes = []\n",
    "modelPreds_2D_noSurface = []\n",
    "\n",
    "for idx in range(len(noSurface_test_images)):\n",
    "    detected_boxes = test(noSurface_test_images[idx], trainer_2D.model, downsample=downsample, alpha=alpha, cutoff=cutoff, plotPrevious=False)\n",
    "    modelPreds_2D_noSurface.append(detected_boxes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "def evaluate_predictions(all_images, all_gt_boxes, all_detected_boxes):\n",
    "    # General metrics\n",
    "    prom_metrics = {\"prom_precision\": [], \"prom_accuracy\": [], \"prom_recall\": [], \"prom_f1_score\": []}\n",
    "\n",
    "    for image, gt_boxes, detected_boxes in zip(all_images, all_gt_boxes, all_detected_boxes):\n",
    "        # Create a copy of the image to avoid modifying the original\n",
    "        image_copy = image.copy()\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(image_copy)\n",
    "\n",
    "        # Ground truth bounding boxes (green)\n",
    "        for gt_box in gt_boxes:\n",
    "            x1, y1, x2, y2 = gt_box\n",
    "            rect = Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=3, edgecolor='black', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "        # Predicted bounding boxes (red)\n",
    "        for detected_box in detected_boxes:\n",
    "            x1, y1, x2, y2 = detected_box\n",
    "            rect = Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=1, edgecolor='r', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        # Individual metrics\n",
    "        precision, recall, f1_score, accuracy, conf_matrix, [fp, fn, tp] = generate_metrics(gt_boxes, detected_boxes)\n",
    "        prom_metrics[\"prom_precision\"].append(precision)\n",
    "        prom_metrics[\"prom_recall\"].append(recall)\n",
    "        prom_metrics[\"prom_f1_score\"].append(f1_score)\n",
    "        prom_metrics[\"prom_accuracy\"].append(accuracy)\n",
    "\n",
    "        print(f'Precision: {precision}')\n",
    "        print(f'Accuracy: {accuracy}')\n",
    "        print(f'Recall: {recall}')\n",
    "        print(f'F1 Score: {f1_score}')\n",
    "\n",
    "        # Confusion Matrix\n",
    "        plot_confusion_matrix(conf_matrix)\n",
    "\n",
    "    # Average results and standard deviation\n",
    "    print(\"-----Average results-----\\n\")\n",
    "    for metric in prom_metrics:\n",
    "        avg_metric = sum(prom_metrics[metric]) / len(prom_metrics[metric])\n",
    "        std_dev = statistics.stdev(prom_metrics[metric])\n",
    "        print(f'Average {metric}: {round(avg_metric, 3)} +/- {round(std_dev, 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Black - Ground truth\n",
    "# Red - Predictions\n",
    "evaluate_predictions(noSurface_test_images, noSurface_groundTruth, modelPreds_2D_noSurface)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
